# AutoCaption
Using deep learning to automatically caption an image.

Example Input:

![example](https://user-images.githubusercontent.com/25394662/34656603-3dd0f62e-f3d1-11e7-8625-3f9f923bdd03.jpg)

Example Output:

<img width="383" alt="screen shot 2018-01-07 at 5 29 39 pm" src="https://user-images.githubusercontent.com/25394662/34656606-433a491c-f3d1-11e7-965a-e2692fd3d36a.png">

Deep Learning Model Used:

![model](https://user-images.githubusercontent.com/25394662/34661219-0a40afc6-f3fd-11e7-8c9b-cbb7b5e0b865.png)



Finalized BLEU scores:

<img width="134" alt="screen shot 2018-01-07 at 5 46 45 pm" src="https://user-images.githubusercontent.com/25394662/34656737-edba3342-f3d2-11e7-82e7-9a2aef9a8afb.png">


5 Steps:
1. Prep Photo Data
2. Prep Text Data
3. Develop Deep Learning Model
4. Evaluate Model
5. Generate New Captions

test images: Flickr8K dataset

Research paper: [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555)
